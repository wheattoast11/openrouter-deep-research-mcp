/**
 * Benchmark Scenario Runner (S1-S6)
 * 
 * Implements standardized benchmark scenarios with:
 * - N=5 repetitions (with warm-up exclusion)
 * - CSV/JSON persistence
 * - Statistical analysis (mean, median, p95, stddev)
 * - Deterministic seeding for reproducibility
 * 
 * SCENARIOS:
 * S1: Simple Chat (single-turn Q&A)
 * S2: RAG (retrieval-augmented generation)
 * S3: Tool Use (function calling)
 * S4: Vision (image understanding)
 * S5: DAG (complex multi-step reasoning)
 * S6: End-to-End (full agent workflow)
 */

const fs = require('fs').promises;
const path = require('path');
const { trace } = require('../utils/logger');
const dbClient = require('../utils/dbClient');

// ============================================================================
// Scenario Definitions
// ============================================================================

const SCENARIOS = {
  S1: {
    id: 'S1',
    name: 'Simple Chat',
    description: 'Single-turn Q&A with minimal context',
    prompts: [
      'What is the capital of France?',
      'Explain quantum entanglement in one sentence.',
      'Convert 100 USD to EUR.',
      'What is 15% of 240?',
      'Name three programming paradigms.'
    ],
    expectedTools: [],
    maxTokens: 150,
    timeout: 10000
  },
  
  S2: {
    id: 'S2',
    name: 'RAG (Retrieval-Augmented Generation)',
    description: 'Query with knowledge retrieval',
    prompts: [
      'What are the key features of MCP protocol v2.2?',
      'How does the agent tool work?',
      'Explain the database schema for jobs.',
      'What is the purpose of BoundedExecutor?',
      'Describe the WebSocket transport layer.'
    ],
    expectedTools: ['search_index', 'query'],
    maxTokens: 300,
    timeout: 20000,
    requiresDb: true
  },
  
  S3: {
    id: 'S3',
    name: 'Tool Use',
    description: 'Function calling and tool orchestration',
    prompts: [
      'Search for "quantum computing" and summarize the results.',
      'Get the current date and calculate days until 2026.',
      'Ping the server and check job status.',
      'List model catalog and set profile to qwen.',
      'Create a benchmark run and measure performance.'
    ],
    expectedTools: ['search_web', 'datetime', 'calc', 'ping', 'model.catalog'],
    maxTokens: 200,
    timeout: 30000
  },
  
  S4: {
    id: 'S4',
    name: 'Vision',
    description: 'Image understanding and multimodal tasks',
    prompts: [
      'Describe this image: [placeholder]',
      'What objects are visible in this scene?',
      'Extract text from this screenshot.',
      'Compare these two images.',
      'Generate a caption for this photo.'
    ],
    expectedTools: [],
    maxTokens: 250,
    timeout: 25000,
    requiresVision: true,
    skip: true // Skip if vision models not available
  },
  
  S5: {
    id: 'S5',
    name: 'DAG (Complex Multi-Step Reasoning)',
    description: 'Multi-step planning and execution with dependencies',
    prompts: [
      'Research the history of AI, then create a timeline.',
      'Find recent papers on transformers, summarize top 3.',
      'Search for "climate change" data, analyze trends.',
      'Get weather for NYC, compare to historical averages.',
      'Research market trends, generate investment thesis.'
    ],
    expectedTools: ['agent', 'search_web', 'search_index'],
    maxTokens: 500,
    timeout: 60000,
    requiresDb: true
  },
  
  S6: {
    id: 'S6',
    name: 'End-to-End Agent Workflow',
    description: 'Full agent cycle: research, synthesis, tool use',
    prompts: [
      'Research "Model Context Protocol" and create a comprehensive report.',
      'Analyze the openrouter-agents codebase structure.',
      'Compare different embedding models and recommend one.',
      'Design a benchmark suite for MCP servers.',
      'Create a technical specification for WebSocket transport.'
    ],
    expectedTools: ['agent', 'search_index', 'search_web', 'query'],
    maxTokens: 1000,
    timeout: 120000,
    requiresDb: true
  }
};

// ============================================================================
// Benchmark Runner
// ============================================================================

/**
 * Run a single scenario
 * @param {string} scenarioId - Scenario ID (S1-S6)
 * @param {Object} options - Configuration options
 * @returns {Promise<Object>} Benchmark results
 */
async function runScenario(scenarioId, options = {}) {
  const scenario = SCENARIOS[scenarioId];
  if (!scenario) {
    throw new Error(`Unknown scenario: ${scenarioId}`);
  }
  
  if (scenario.skip) {
    trace({ type: 'benchmark:skip', scenario: scenarioId, reason: 'Not available' });
    return { scenarioId, status: 'skipped', reason: 'Not available' };
  }
  
  const {
    repetitions = 5,
    warmup = 1,
    toolExecutor,
    modelProfile,
    outputDir = './test-results/benchmarks'
  } = options;
  
  trace({ type: 'benchmark:start', scenario: scenarioId, repetitions, warmup });
  
  // Create benchmark run in database
  const runId = `${scenarioId}-${Date.now()}`;
  await dbClient.createBenchmarkRun({
    run_id: runId,
    scenario_id: scenarioId,
    model_profile: modelProfile || { id: 'default' },
    config: { repetitions, warmup, ...scenario }
  });
  
  const results = [];
  
  // Run with warm-up
  for (let i = 0; i < repetitions + warmup; i++) {
    const isWarmup = i < warmup;
    const promptIdx = i % scenario.prompts.length;
    const prompt = scenario.prompts[promptIdx];
    
    trace({ type: 'benchmark:iteration', scenario: scenarioId, iteration: i, isWarmup, prompt: prompt.substring(0, 50) });
    
    const startTime = Date.now();
    let success = false;
    let error = null;
    let response = null;
    let toolsCalled = [];
    
    try {
      // Execute the prompt using the tool executor
      response = await executePrompt(prompt, scenario, toolExecutor);
      success = true;
      toolsCalled = response.toolsCalled || [];
    } catch (e) {
      error = e.message;
      trace({ type: 'benchmark:error', scenario: scenarioId, iteration: i, error: e.message });
    }
    
    const endTime = Date.now();
    const latency = endTime - startTime;
    
    // Store measurement in database
    await dbClient.insertBenchmarkMeasurement({
      run_id: runId,
      iteration: i,
      is_warmup: isWarmup,
      latency_ms: latency,
      success,
      error,
      tools_called: toolsCalled,
      prompt_length: prompt.length,
      response_length: response?.text?.length || 0,
      timestamp: new Date().toISOString()
    });
    
    // Only include non-warmup results
    if (!isWarmup) {
      results.push({
        iteration: i - warmup,
        latency,
        success,
        error,
        toolsCalled,
        promptLength: prompt.length,
        responseLength: response?.text?.length || 0
      });
    }
  }
  
  // Calculate statistics
  const latencies = results.filter(r => r.success).map(r => r.latency);
  const stats = calculateStatistics(latencies);
  
  // Mark run as finished
  await dbClient.finishBenchmarkRun(runId);
  
  const result = {
    scenarioId,
    runId,
    scenario: scenario.name,
    description: scenario.description,
    repetitions: results.length,
    warmup,
    timestamp: new Date().toISOString(),
    results,
    statistics: stats,
    successRate: results.filter(r => r.success).length / results.length
  };
  
  // Persist to CSV and JSON
  await persistResults(result, outputDir);
  
  trace({ type: 'benchmark:complete', scenario: scenarioId, stats });
  
  return result;
}

/**
 * Run all scenarios (S1-S6)
 */
async function runAllScenarios(options = {}) {
  const scenarioIds = Object.keys(SCENARIOS);
  const results = [];
  
  for (const scenarioId of scenarioIds) {
    try {
      const result = await runScenario(scenarioId, options);
      results.push(result);
    } catch (e) {
      trace({ type: 'benchmark:scenario:error', scenario: scenarioId, error: e.message });
      results.push({
        scenarioId,
        status: 'error',
        error: e.message
      });
    }
  }
  
  // Generate summary report
  const summary = generateSummaryReport(results);
  
  // Persist summary
  const outputDir = options.outputDir || './test-results/benchmarks';
  await fs.mkdir(outputDir, { recursive: true });
  await fs.writeFile(
    path.join(outputDir, `benchmark-summary-${Date.now()}.json`),
    JSON.stringify(summary, null, 2)
  );
  
  return summary;
}

// ============================================================================
// Helper Functions
// ============================================================================

/**
 * Execute a prompt using the appropriate tool
 */
async function executePrompt(prompt, scenario, toolExecutor) {
  if (!toolExecutor) {
    // Mock execution for testing
    await new Promise(resolve => setTimeout(resolve, Math.random() * 100 + 50));
    return { text: 'Mock response', toolsCalled: [] };
  }
  
  // Determine which tool to use based on scenario
  if (scenario.id === 'S1') {
    // Simple chat - no tools needed
    return { text: 'Simple response', toolsCalled: [] };
  } else if (scenario.id === 'S2' || scenario.id === 'S5' || scenario.id === 'S6') {
    // Use agent tool
    const result = await toolExecutor.call('agent', {
      action: 'auto',
      query: prompt,
      max_turns: scenario.id === 'S6' ? 5 : 3
    });
    return result;
  } else if (scenario.id === 'S3') {
    // Tool use - call search_web or similar
    const result = await toolExecutor.call('search_web', {
      query: prompt.split(' ').slice(0, 5).join(' '),
      maxResults: 3
    });
    return result;
  }
  
  return { text: 'Default response', toolsCalled: [] };
}

/**
 * Calculate statistics from latency array
 */
function calculateStatistics(latencies) {
  if (latencies.length === 0) {
    return { mean: 0, median: 0, p95: 0, p99: 0, min: 0, max: 0, stddev: 0 };
  }
  
  const sorted = [...latencies].sort((a, b) => a - b);
  const mean = latencies.reduce((a, b) => a + b, 0) / latencies.length;
  const median = sorted[Math.floor(sorted.length / 2)];
  const p95 = sorted[Math.floor(sorted.length * 0.95)];
  const p99 = sorted[Math.floor(sorted.length * 0.99)];
  const min = sorted[0];
  const max = sorted[sorted.length - 1];
  
  // Standard deviation
  const variance = latencies.reduce((sum, val) => sum + Math.pow(val - mean, 2), 0) / latencies.length;
  const stddev = Math.sqrt(variance);
  
  return { mean, median, p95, p99, min, max, stddev };
}

/**
 * Persist results to CSV and JSON
 */
async function persistResults(result, outputDir) {
  await fs.mkdir(outputDir, { recursive: true });
  
  const baseFilename = `${result.scenarioId}-${Date.now()}`;
  
  // JSON
  await fs.writeFile(
    path.join(outputDir, `${baseFilename}.json`),
    JSON.stringify(result, null, 2)
  );
  
  // CSV
  const csvHeader = 'iteration,latency_ms,success,error,tools_called,prompt_length,response_length\n';
  const csvRows = result.results.map(r => 
    `${r.iteration},${r.latency},${r.success},${r.error || ''},${r.toolsCalled.join(';')},${r.promptLength},${r.responseLength}`
  ).join('\n');
  
  await fs.writeFile(
    path.join(outputDir, `${baseFilename}.csv`),
    csvHeader + csvRows
  );
  
  trace({ type: 'benchmark:persist', scenario: result.scenarioId, outputDir });
}

/**
 * Generate summary report across all scenarios
 */
function generateSummaryReport(results) {
  const summary = {
    timestamp: new Date().toISOString(),
    totalScenarios: results.length,
    completed: results.filter(r => r.statistics).length,
    failed: results.filter(r => r.status === 'error').length,
    skipped: results.filter(r => r.status === 'skipped').length,
    scenarios: {}
  };
  
  for (const result of results) {
    if (result.statistics) {
      summary.scenarios[result.scenarioId] = {
        name: result.scenario,
        successRate: result.successRate,
        meanLatency: result.statistics.mean,
        p95Latency: result.statistics.p95,
        repetitions: result.repetitions
      };
    } else {
      summary.scenarios[result.scenarioId] = {
        status: result.status,
        error: result.error
      };
    }
  }
  
  return summary;
}

// ============================================================================
// Exports
// ============================================================================

module.exports = {
  SCENARIOS,
  runScenario,
  runAllScenarios,
  calculateStatistics
};

// CLI execution
if (require.main === module) {
  const runCli = async () => {
    console.log('üèÅ Benchmark Scenario Runner (S1-S6)\n');
    
    const args = process.argv.slice(2);
    const scenarioId = args[0] || 'all';
    
    if (scenarioId === 'all') {
      console.log('Running all scenarios...\n');
      const summary = await runAllScenarios({ repetitions: 5, warmup: 1 });
      console.log('\nüìä Summary:');
      console.log(JSON.stringify(summary, null, 2));
    } else {
      console.log(`Running scenario ${scenarioId}...\n`);
      const result = await runScenario(scenarioId, { repetitions: 5, warmup: 1 });
      console.log('\nüìä Results:');
      console.log(JSON.stringify(result.statistics, null, 2));
    }
  };
  
  runCli().catch(console.error);
}

